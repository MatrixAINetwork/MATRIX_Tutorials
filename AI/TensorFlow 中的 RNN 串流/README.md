## TensorFlow 中的 RNN 串流

谋智（Mozilla）研究所的机器学习团队正在开发一个自动语音识别引擎，它将作为深度语音（DeepSpeech）项目的一部分，致力于向开发人员开放语音识别技术和预训练模型。我们正在努力提高我们开源的语音转文本引擎的性能和易用性。即将发布的 0.2 版本将包括一个大家期待已久的特性：在录制音频时实时进行语音识别的能力。这篇博客文章描述了我们是怎样修改 STT（即 speech-to-text，语音转文字）引擎的架构，来达到实现实时转录的性能要求。不久之后，等到正式版本发布，你就可以体验这一音频转换的功能。

当将神经网络应用到诸如音频或文本的顺序数据时，捕获数据随着时间推移而出现的模式是很重要的。循环神经网络（RNN）是具有『记忆』的神经网络 —— 它们不仅将数据中的下一个元素作为输入，而且还将随时间演进的状态作为输入，并使用这个状态来捕获与时间相关的模式。有时，你可能希望捕获依赖未来数据的模式。解决这个问题的方法之一是使用两个 RNN，一个在时序上向前，而另一个按向后的时序（即从数据中的最后一个元素开始，到第一个元素）。你可以在 Chris Olah 的这篇文章中了解更多关于 RNN（以及关于 DeepSpeech 中使用的特定类型的 RNN）的知识。


### 使用双向 RNN

DeepSpeech 的当前版本使用了用 TensorFlow 实现的双向 RNN，这意味着它需要在开始工作之前具有整个可用的输入。一种改善这种情况的方法是通过实现流式模型：在数据到达时以块为单位进行工作，这样当输入结束时，模型已经在处理它，并且可以更快地给出结果。你也可以尝试在输入中途查看部分结果。

![](https://user-gold-cdn.xitu.io/2018/10/20/1669199d02ead983?imageslim)



    这个动画展示了数据如何在网络间流动。数据通过三个全连接层，从音频输入转变成特征计算。然后通过了一个双向 RNN 层，最后通过对单个时间步长进行预测的全连接层。


为了做到这一点，你需要有一个可以分块处理数据的模型。这是当前模型的图表，显示数据如何流过它。

可以看到，在双向 RNN 中，倒数第二步的计算需要最后一步的数据，倒数第三步的计算需要倒数第二步的数据……如此循环往复。这些是图中从右到左的红色箭头。

通过在数据被馈入时进行到第三层的计算，我们可以实现部分流式处理。这种方法的问题是它在延迟方面不会给我们带来太多好处：第四层和第五层占用了整个模型几乎一半的计算成本。


### 使用单向 RNN 处理串流

因此，我们可以用单向层替换双向层，单向层不依赖于将来的时间步。只要我们有足够的音频输入，就能一直计算到最后一层。


使用单向模型，你可以分段地提供输入，而不是在同一时间输入整个输入并获得整个输出。也就是说，你可以一次输入 100ms 的音频，立即获得这段时间的输出，并保存最终状态，这样可以将其用作下一个 100ms 的音频的初始状态。


![](https://user-gold-cdn.xitu.io/2018/10/20/1669199d329b3298?imageslim)


    一种使用单向 RNN 的备选架构，其中每个时间步长仅取决于即时的输入和来自前一步的状态。


